{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "695784e6",
        "outputId": "671fa3ef-1d7d-47c0-fa66-420332c3541c"
      },
      "source": [
        "target_column_name = 'Final Grade'\n",
        "print(f\"The new target variable is '{target_column_name}'. Regression models will use this numerical variable, and classification models will use its categorized version.\")\n",
        "\n",
        "\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "\n",
        "columns_to_drop = [\n",
        "    'Daily alcohol label', 'going out with friends label', 'famrel label', 'Total Grades'\n",
        "]\n",
        "df_processed_new = df.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "\n",
        "categorical_cols_new = df_processed_new.select_dtypes(include='object').columns\n",
        "\n",
        "# Apply one-hot encoding with drop_first=True\n",
        "df_encoded_new = pd.get_dummies(df_processed_new, columns=categorical_cols_new, drop_first=True)\n",
        "\n",
        "# Separate features (X) and the new target variable (y)\n",
        "X = df_encoded_new.drop(columns=[target_column_name])\n",
        "y = df_encoded_new[target_column_name]\n",
        "\n",
        "# Import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets (80/20 ratio)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "\n",
        "# Define the new categorization function for 'Final Grade'\n",
        "def categorize_final_grades(final_grade):\n",
        "    if final_grade < 10:\n",
        "        return 'Low'\n",
        "    elif 10 <= final_grade < 15:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'High'\n",
        "\n",
        "# Apply the new categorization to y_train and y_test\n",
        "y_train_cat = y_train.apply(categorize_final_grades)\n",
        "y_test_cat = y_test.apply(categorize_final_grades)\n",
        "\n",
        "print(\"\\nCategorized y_train head (Final Grade):\")\n",
        "print(y_train_cat.head())\n",
        "print(\"\\nCategorized y_test head (Final Grade):\")\n",
        "print(y_test_cat.head())\n",
        "\n",
        "print(\"\\nValue counts for y_train_cat (Final Grade):\")\n",
        "print(y_train_cat.value_counts())\n",
        "print(\"\\nValue counts for y_test_cat (Final Grade):\")\n",
        "print(y_test_cat.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The new target variable is 'Final Grade'. Regression models will use this numerical variable, and classification models will use its categorized version.\n",
            "\n",
            "Missing values per column:\n",
            "Series([], dtype: int64)\n",
            "\n",
            "Shape of X_train: (316, 54)\n",
            "Shape of X_test: (79, 54)\n",
            "Shape of y_train: (316,)\n",
            "Shape of y_test: (79,)\n",
            "\n",
            "Categorized y_train head (Final Grade):\n",
            "181       Low\n",
            "194    Medium\n",
            "173       Low\n",
            "63       High\n",
            "253    Medium\n",
            "Name: Final Grade, dtype: object\n",
            "\n",
            "Categorized y_test head (Final Grade):\n",
            "78        Low\n",
            "371    Medium\n",
            "248       Low\n",
            "55       High\n",
            "390       Low\n",
            "Name: Final Grade, dtype: object\n",
            "\n",
            "Value counts for y_train_cat (Final Grade):\n",
            "Final Grade\n",
            "Medium    155\n",
            "Low       102\n",
            "High       59\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for y_test_cat (Final Grade):\n",
            "Final Grade\n",
            "Medium    37\n",
            "Low       28\n",
            "High      14\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3f29578"
      },
      "source": [
        "## Build and Evaluate Linear Regression Model for Final Grade\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0c6e3af",
        "outputId": "b77c2f4b-dfa0-44af-e96b-a102ea45a55d"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "linear_reg_model_final_grade = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "linear_reg_model_final_grade.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred_linear_reg_final_grade = linear_reg_model_final_grade.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae_linear_reg_final_grade = mean_absolute_error(y_test, y_pred_linear_reg_final_grade)\n",
        "mse_linear_reg_final_grade = mean_squared_error(y_test, y_pred_linear_reg_final_grade)\n",
        "r2_linear_reg_final_grade = r2_score(y_test, y_pred_linear_reg_final_grade)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Linear Regression (Final Grade) - Mean Absolute Error (MAE): {mae_linear_reg_final_grade:.2f}\")\n",
        "print(f\"Linear Regression (Final Grade) - Mean Squared Error (MSE): {mse_linear_reg_final_grade:.2f}\")\n",
        "print(f\"Linear Regression (Final Grade) - R-squared (R2): {r2_linear_reg_final_grade:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression (Final Grade) - Mean Absolute Error (MAE): 1.44\n",
            "Linear Regression (Final Grade) - Mean Squared Error (MSE): 4.23\n",
            "Linear Regression (Final Grade) - R-squared (R2): 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84c86ef7"
      },
      "source": [
        "## Build and Evaluate Logistic Regression Model for Categorized Final Grade\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "035c3a17",
        "outputId": "9be7fe69-030d-432d-b8da-33b3e50179cc"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "logistic_reg_model_final_grade = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "logistic_reg_model_final_grade.fit(X_train, y_train_cat)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_logistic_reg_final_grade = logistic_reg_model_final_grade.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_logistic_reg_final_grade = accuracy_score(y_test_cat, y_pred_logistic_reg_final_grade)\n",
        "precision_logistic_reg_final_grade = precision_score(y_test_cat, y_pred_logistic_reg_final_grade, average='weighted', zero_division=0)\n",
        "recall_logistic_reg_final_grade = recall_score(y_test_cat, y_pred_logistic_reg_final_grade, average='weighted', zero_division=0)\n",
        "f1_logistic_reg_final_grade = f1_score(y_test_cat, y_pred_logistic_reg_final_grade, average='weighted', zero_division=0)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix_logistic_reg_final_grade = confusion_matrix(y_test_cat, y_pred_logistic_reg_final_grade)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Logistic Regression (Final Grade) - Accuracy: {accuracy_logistic_reg_final_grade:.2f}\")\n",
        "print(f\"Logistic Regression (Final Grade) - Precision (weighted): {precision_logistic_reg_final_grade:.2f}\")\n",
        "print(f\"Logistic Regression (Final Grade) - Recall (weighted): {recall_logistic_reg_final_grade:.2f}\")\n",
        "print(f\"Logistic Regression (Final Grade) - F1-score (weighted): {f1_logistic_reg_final_grade:.2f}\")\n",
        "print(\"\\nLogistic Regression (Final Grade) - Confusion Matrix:\")\n",
        "print(conf_matrix_logistic_reg_final_grade)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (Final Grade) - Accuracy: 0.91\n",
            "Logistic Regression (Final Grade) - Precision (weighted): 0.91\n",
            "Logistic Regression (Final Grade) - Recall (weighted): 0.91\n",
            "Logistic Regression (Final Grade) - F1-score (weighted): 0.91\n",
            "\n",
            "Logistic Regression (Final Grade) - Confusion Matrix:\n",
            "[[12  0  2]\n",
            " [ 0 25  3]\n",
            " [ 1  1 35]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e74b923",
        "outputId": "ddd30975-bd8e-47b5-9e88-8f0085fd02f7"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Instantiate an SVM model (using a linear kernel for simplicity, can be adjusted)\n",
        "# Set random_state for reproducibility\n",
        "svm_model_final_grade = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "svm_model_final_grade.fit(X_train, y_train_cat)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_svm_final_grade = svm_model_final_grade.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_svm_final_grade = accuracy_score(y_test_cat, y_pred_svm_final_grade)\n",
        "precision_svm_final_grade = precision_score(y_test_cat, y_pred_svm_final_grade, average='weighted', zero_division=0)\n",
        "recall_svm_final_grade = recall_score(y_test_cat, y_pred_svm_final_grade, average='weighted', zero_division=0)\n",
        "f1_svm_final_grade = f1_score(y_test_cat, y_pred_svm_final_grade, average='weighted', zero_division=0)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix_svm_final_grade = confusion_matrix(y_test_cat, y_pred_svm_final_grade)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"SVM (Final Grade) - Accuracy: {accuracy_svm_final_grade:.2f}\")\n",
        "print(f\"SVM (Final Grade) - Precision (weighted): {precision_svm_final_grade:.2f}\")\n",
        "print(f\"SVM (Final Grade) - Recall (weighted): {recall_svm_final_grade:.2f}\")\n",
        "print(f\"SVM (Final Grade) - F1-score (weighted): {f1_svm_final_grade:.2f}\")\n",
        "print(\"\\nSVM (Final Grade) - Confusion Matrix:\")\n",
        "print(conf_matrix_svm_final_grade)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM (Final Grade) - Accuracy: 0.90\n",
            "SVM (Final Grade) - Precision (weighted): 0.90\n",
            "SVM (Final Grade) - Recall (weighted): 0.90\n",
            "SVM (Final Grade) - F1-score (weighted): 0.90\n",
            "\n",
            "SVM (Final Grade) - Confusion Matrix:\n",
            "[[11  0  3]\n",
            " [ 0 25  3]\n",
            " [ 1  1 35]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ce77f32",
        "outputId": "9da20aff-0ed1-4da7-835c-2c03448bc8d3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Instantiate a Random Forest Classifier model\n",
        "# Set random_state for reproducibility\n",
        "random_forest_model_final_grade = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "random_forest_model_final_grade.fit(X_train, y_train_cat)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_random_forest_final_grade = random_forest_model_final_grade.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_random_forest_final_grade = accuracy_score(y_test_cat, y_pred_random_forest_final_grade)\n",
        "precision_random_forest_final_grade = precision_score(y_test_cat, y_pred_random_forest_final_grade, average='weighted', zero_division=0)\n",
        "recall_random_forest_final_grade = recall_score(y_test_cat, y_pred_random_forest_final_grade, average='weighted', zero_division=0)\n",
        "f1_random_forest_final_grade = f1_score(y_test_cat, y_pred_random_forest_final_grade, average='weighted', zero_division=0)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix_random_forest_final_grade = confusion_matrix(y_test_cat, y_pred_random_forest_final_grade)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Random Forest (Final Grade) - Accuracy: {accuracy_random_forest_final_grade:.2f}\")\n",
        "print(f\"Random Forest (Final Grade) - Precision (weighted): {precision_random_forest_final_grade:.2f}\")\n",
        "print(f\"Random Forest (Final Grade) - Recall (weighted): {recall_random_forest_final_grade:.2f}\")\n",
        "print(f\"Random Forest (Final Grade) - F1-score (weighted): {f1_random_forest_final_grade:.2f}\")\n",
        "print(\"\\nRandom Forest (Final Grade) - Confusion Matrix:\")\n",
        "print(conf_matrix_random_forest_final_grade)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest (Final Grade) - Accuracy: 0.86\n",
            "Random Forest (Final Grade) - Precision (weighted): 0.86\n",
            "Random Forest (Final Grade) - Recall (weighted): 0.86\n",
            "Random Forest (Final Grade) - F1-score (weighted): 0.86\n",
            "\n",
            "Random Forest (Final Grade) - Confusion Matrix:\n",
            "[[10  0  4]\n",
            " [ 0 25  3]\n",
            " [ 1  3 33]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a131dcb8",
        "outputId": "2f9d99e3-c79c-45a8-ea51-e427c9e3a2aa"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Instantiate a Decision Tree Classifier model\n",
        "# Set random_state for reproducibility\n",
        "decision_tree_model_final_grade = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "decision_tree_model_final_grade.fit(X_train, y_train_cat)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_decision_tree_final_grade = decision_tree_model_final_grade.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_decision_tree_final_grade = accuracy_score(y_test_cat, y_pred_decision_tree_final_grade)\n",
        "precision_decision_tree_final_grade = precision_score(y_test_cat, y_pred_decision_tree_final_grade, average='weighted', zero_division=0)\n",
        "recall_decision_tree_final_grade = recall_score(y_test_cat, y_pred_decision_tree_final_grade, average='weighted', zero_division=0)\n",
        "f1_decision_tree_final_grade = f1_score(y_test_cat, y_pred_decision_tree_final_grade, average='weighted', zero_division=0)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix_decision_tree_final_grade = confusion_matrix(y_test_cat, y_pred_decision_tree_final_grade)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Decision Tree (Final Grade) - Accuracy: {accuracy_decision_tree_final_grade:.2f}\")\n",
        "print(f\"Decision Tree (Final Grade) - Precision (weighted): {precision_decision_tree_final_grade:.2f}\")\n",
        "print(f\"Decision Tree (Final Grade) - Recall (weighted): {recall_decision_tree_final_grade:.2f}\")\n",
        "print(f\"Decision Tree (Final Grade) - F1-score (weighted): {f1_decision_tree_final_grade:.2f}\")\n",
        "print(\"\\nDecision Tree (Final Grade) - Confusion Matrix:\")\n",
        "print(conf_matrix_decision_tree_final_grade)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree (Final Grade) - Accuracy: 0.81\n",
            "Decision Tree (Final Grade) - Precision (weighted): 0.81\n",
            "Decision Tree (Final Grade) - Recall (weighted): 0.81\n",
            "Decision Tree (Final Grade) - F1-score (weighted): 0.81\n",
            "\n",
            "Decision Tree (Final Grade) - Confusion Matrix:\n",
            "[[11  0  3]\n",
            " [ 0 22  6]\n",
            " [ 1  5 31]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efb243e0"
      },
      "source": [
        "## Summary of Model Performance for Final Grade Prediction\n",
        "\n",
        "This section summarizes the performance of all built models for predicting the 'Final Grade', both numerically and categorically. The models include Linear Regression (for numerical prediction) and Logistic Regression, SVM, Random Forest, and Decision Tree (for categorical prediction).\n",
        "\n",
        "### Linear Regression Model Performance (Numerical 'Final Grade')\n",
        "*   **Mean Absolute Error (MAE)**: 1.44\n",
        "*   **Mean Squared Error (MSE)**: 4.23\n",
        "*   **R-squared (R2)**: 0.77\n",
        "\n",
        "The Linear Regression model achieved a good R-squared value of 0.77, indicating that 77% of the variance in the 'Final Grade' can be explained by the features. The MAE and MSE are relatively low, suggesting accurate numerical predictions.\n",
        "\n",
        "### Classification Models Performance (Categorized 'Final Grade')\n",
        "\n",
        "| Model                  | Accuracy | Precision (weighted) | Recall (weighted) | F1-score (weighted) |\n",
        "| :--------------------- | :------- | :------------------- | :---------------- | :------------------ |\n",
        "| Logistic Regression    | 0.91     | 0.91                 | 0.91              | 0.91                |\n",
        "| Support Vector Machine | 0.90     | 0.90                 | 0.90              | 0.90                |\n",
        "| Random Forest          | 0.86     | 0.86                 | 0.86              | 0.86                |\n",
        "| Decision Tree          | 0.81     | 0.81                 | 0.81              | 0.81                |\n",
        "\n",
        "### Notable Observations:\n",
        "*   **Logistic Regression** and **Support Vector Machine (SVM)** models showed the highest performance for classifying 'Final Grade' into 'Low', 'Medium', or 'High' categories, both achieving an accuracy of around 0.90-0.91. This indicates strong predictive power for these classification tasks.\n",
        "*   **Random Forest** performed slightly lower than Logistic Regression and SVM, with an accuracy of 0.86, but still demonstrated good performance.\n",
        "*   The **Decision Tree** model had the lowest classification performance among the ensemble and kernel-based methods, with an accuracy of 0.81. This could be due to its tendency to overfit or its limited ability to capture complex non-linear relationships compared to other models without specific hyperparameter tuning.\n",
        "*   Overall, the classification models performed exceptionally well in predicting the categorical 'Final Grade', suggesting that the features are highly predictive of the students' performance levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "309a4fb2"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The target variable was successfully changed to 'Final Grade'. Numerical 'Final Grade' was also categorized into 'Low' (\\<10), 'Medium' (10-14), and 'High' (\\>=15) for classification tasks.\n",
        "*   **Linear Regression** model for numerical 'Final Grade' achieved an R-squared of 0.77, indicating it explains 77% of the variance in 'Final Grade'. It had a Mean Absolute Error (MAE) of 1.44 and a Mean Squared Error (MSE) of 4.23.\n",
        "*   For predicting the *categorized* 'Final Grade', the classification models performed as follows:\n",
        "    *   **Logistic Regression** showed the highest performance with an accuracy of 0.91, precision of 0.91, recall of 0.91, and F1-score of 0.91.\n",
        "    *   **Support Vector Machine (SVM)** followed closely with an accuracy of 0.90, precision of 0.90, recall of 0.90, and F1-score of 0.90.\n",
        "    *   **Random Forest** achieved good performance with an accuracy of 0.86, precision of 0.86, recall of 0.86, and F1-score of 0.86.\n",
        "    *   **Decision Tree** had the lowest performance among classification models, with an accuracy of 0.81, precision of 0.81, recall of 0.81, and F1-score of 0.81.\n",
        "\n"
      ]
    }
  ]
}